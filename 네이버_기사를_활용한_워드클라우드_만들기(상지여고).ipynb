{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트를 활용한 단어 구름 만들기 1 : 메모장 텍스트 단어 구름 만들기\n",
        "\n",
        "1. 단어구름이란? : 텍스트에 사용된 단어의 사용빈도에 따라 단어의 크기를 결정하고 사용된 단어와 빈도를 바탕으로 텍스트를 한 장의 단어구름으로 시각화 한 것\n",
        "\n",
        "2. 첫 번째 과정으로 메모장으로 열 수 있는 텍스트 파일과 글씨체 파일을 활용하여 단어구름을 생성하는 작업을 수행해보겠습니다!"
      ],
      "metadata": {
        "id": "8m30GEfHqmV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#워드 클라우드 생성을 위한 프로그래밍 도구 불러오기\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS"
      ],
      "metadata": {
        "id": "5zDs_B07qfcT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "print(text)\n",
        "wordcloud = WordCloud(font_path = \"\",background_color='white').generate(text)\n",
        "plt.figure(figsize=(15,15)) #이미지 사이즈 지정\n",
        "plt.imshow(wordcloud, interpolation='lanczos') #wordcloud안에 들어있는 설정값을 이용하여 시각화를 하고 그 결과값을 저장, 뒤에 있는 것은 부드러움의 정도 (신경X)\n",
        "plt.axis('off') #x y 축 숫자 제거\n",
        "plt.savefig('') #위에서 만든 결과값을 파일로 만듦\n",
        "plt.show()  #최종 결과를 그림으로 보여줌\n"
      ],
      "metadata": {
        "id": "1OCQGxQuyxat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 텍스트 파일과 ColorMap을 설정한 상세한 단어구름 만들기\n",
        "* 컴퓨터에서 데이터를 처리할 때는 보통 파일 단위로 처리하는게 일상입니다.\n",
        "* 선생님들이 가지고 계신 텍스트, 혹은 탐색한 텍스트를 메모장에 저장하시고 이를 코랩에 업로드 한 후 단어구름으로 만들어봅시다!\n",
        "* 색깔의 범위는 colormap에서 설정할 수 있으며 활용할 수 있는 예시는 다음과 같습니다.\n",
        "* 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'o...\n",
        "* 배경 색깔 background_color은 https://encycolorpedia.kr/html 에서 찾을 수 있다"
      ],
      "metadata": {
        "id": "4AS73pKj0Mmx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk6p0oVOu-Gh"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS #시각화를 위한 도구인 wordcloud(전체)에서 시각화를 담당하는 WordCloud도구와, 특정 단어를 제거할 수 있는 STOPWORDS 도구를 불러옴\n",
        "\n",
        "f = open('','r') #* 파일 입력 클래스룸에서 다운받아 DPL에 집어놓은 moon.txt 파일 이름을 입력\n",
        "\n",
        "data = f.read()\n",
        "#print(data)\n",
        "\n",
        "spwords=set(STOPWORDS) # 기본적으로 많이 쓰는 단어 (제외할 단어) # ex)'should', \"wouldn't\", \"how's\", \"i'm\", 'then', etc ..\n",
        "spwords.add('') #제외하고 싶은 단어 추가 * 시각화에서 큰 의미가 없는 단어들을 최소 3개 이상 채우기\n",
        "spwords.add('') #제외하고 싶은 단어 추가\n",
        "spwords.add('') #제외하고 싶은 단어 추가\n",
        "spwords.add('') #제외하고 싶은 단어 추가\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=200, font_path='',    #폰트 크기, 폰트 경로, 제외할 단어, 배경색, 크기.generate(대상이 되는 글자)\n",
        "                     stopwords=spwords,\n",
        "                     colormap='',\n",
        "                     background_color='#1e90ff',\n",
        "                     width=1200,height=800).generate(data)\n",
        "\n",
        "plt.figure(figsize=(10,8)) #크기 지정\n",
        "plt.imshow(wordcloud) #이미지 생성\n",
        "plt.tight_layout(pad=0) #여백 설정\n",
        "plt.axis('off') #x,y축 값 삭제\n",
        "plt.savefig('') #DPL에 moon.png로 파일 생성\n",
        "plt.show() #생성된 시각화 보여주기\n",
        "f.close() #파일 사용 마지막"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 네이버 뉴스 기사 자료 검색하여 파일로 저장하기\n",
        "\n",
        "* 앞에서 수행한 활동을 참고하면 어떤 텍스트가 주어지더라도 단어구름을 생성할 수 있습니다.\n",
        "* 그런데 실시간으로 많은 내용이 생성되는 네이버 기사를 활용할 수는 없는 걸까요?\n",
        "* 여기서는 네이버 API를 활용하여 키워드에 대한 뉴스 기사를 검색하여 파일로 저장하고\n",
        "* 이를 활용하여 단어구름의 대상 텍스트를 생성하는 프로그래밍을 진행해보겠습니다."
      ],
      "metadata": {
        "id": "S96gG83i1XDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#날짜를 불러오기 위해 필요한 프로그래밍 도구 설지\n",
        "\n",
        "!pip install pytz"
      ],
      "metadata": {
        "id": "rph5hrQK4egh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기사에 대한 기본 정보 CSV 파일로 저장하기\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from pprint import pprint\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "#네이버 검색 키워드를 입력받고 주소와 API 키를 이용하여 결과를 받아와 이를 파일로 저장\n",
        "keyword = input('검색 키워드:')\n",
        "url = 'https://openapi.naver.com/v1/search/news.json?query={}'\n",
        "headers = {\n",
        "    'X-Naver-Client-Id':'',\n",
        "    'X-Naver-Client-Secret':\"\"\n",
        "}\n",
        "\n",
        "res = requests.get(url.format(keyword), headers=headers)\n",
        "\n",
        "if res.status_code == 200:\n",
        "    #pprint(res.json())\n",
        "    datas = res.json()\n",
        "    print('총 검색 건수 : ', datas['total'])\n",
        "    #print(type(datas), type(datas['items']))\n",
        "    #print('----------------------------------------------------------------------------------')\n",
        "    #pprint(datas['items'])\n",
        "    df=pd.DataFrame(datas['items'])\n",
        "    #df.to_csv('naver_{}_검색결과.csv'.format(keyword), encoding='utf-8-sig', index=False)\n",
        "\n",
        "\n",
        "#기사에 있는 여러 태그들을 삭제함\n",
        "def clean_html(x):\n",
        "  x = re.sub(\"\\&\\w*\\;\",\"\",x)\n",
        "  x = re.sub(\"<.*?>\",\"\",x)\n",
        "  x = re.sub(\"\\n\", \"\", x)       # 개행문자 제거\n",
        "  x = re.sub(\"\\t\", \"\", x)       # 탭 문자 제거\n",
        "  x = re.sub('\\n', \"\", x)       # 개행문자 제거\n",
        "  x = re.sub('\\t', \"\", x)       # 탭 문자 제거\n",
        "  return x\n",
        "\n",
        "df['title'] = df['title'].apply(lambda x: clean_html(x))\n",
        "df['description'] = df['description'].apply(lambda x: clean_html(x))\n",
        "\n",
        "#코드를 실행한 시점의 연월시를 저장함\n",
        "\n",
        "\n",
        "kst = pytz.timezone('Asia/Seoul')\n",
        "current_time = datetime.now(kst)\n",
        "current_time_str = current_time.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "df.to_csv('naver_{}_검색결과_{}.csv'.format(keyword,current_time_str), encoding='utf-8-sig', index=False)\n",
        "naver_title = 'naver_{}_검색결과_{}.csv'.format(keyword,current_time_str)\n",
        "print(naver_title)\n",
        "\n",
        "f=open(\"{}_{}.txt\".format(keyword,current_time_str),'w',encoding='utf-8-sig')\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  f.write(row['description'])\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "zJbgZBea1pKl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}